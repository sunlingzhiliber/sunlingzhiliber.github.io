---
layout:     post
title:      锁和并发
date:       2018-07-10
author:     Liber Sun
header-img: img/post-basic.jpg
catalog: true
tags:
    - 面试之路
---


# 并发

我们首先来了解并发的三个核心概念。

1. `原子性`

线程是CPU调度的基本单位。CPU有时间片的概念，会根据不同的调度算法进行线程调度。所以在多线程场景下，就会发生原子性问题。因为线程在执行一个读改写操作时，在执行完读改之后，时间片耗完，就会被要求放弃CPU，并等待重新调度。

保证原子性就是保证，一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

在java中，对基本数据类型的变量的读取和赋值操作都是原子性操作，即这些操作是不可中断的。Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。

2. `可见性`
现代计算机中，由于 CPU 直接从主内存中读取数据的效率不高，所以都会对应的 CPU 高速缓存，先将主内存中的数据读取到缓存中，线程修改数据之后首先更新到缓存，之后才会更新到主内存。如果此时还没有将数据更新到主内存其他的线程此时来读取就是修改之前的数据。

在CPU和主存之间增加缓存，在多线程场景下就可能存在缓存一致性问题，也就是说，在多核CPU中，每个核的自己的缓存中，关于同一个数据的缓存内容可能不一致。

可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

Java提供了volatile关键字来保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。

另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。

3. `有序性`

有序性：即程序执行的顺序按照代码的先后顺序执行。

为了CPU最大限度的使用，进行处理器优化。
Java虚拟机的即时编译器(JIT)，会进行指令重排。

```java
   int a=100;//step1
   int b=200;//step2
   int c=a+b;//step3
```

对于以上的代码，正常的执行顺序是`1>>2>>3`。但是JVM有时为了提高整体效率，可能会对指令进行重排序导致最终顺序为`2>>1>>3`。当然JVM不会随意重排，重排的前提是最终结果和代码执行顺序结果应该一致。

重排在单线程中不会存在问题，在多线程会出现数据不一致的问题。

在Java里面，可以通过volatile关键字来保证一定的“有序性”。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。

另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。

在JDK中，JAVA语言为了维持顺序内部的顺序化语义，也就是为了保证程序的最终运行结果需要和在单线程严格意义的顺序化环境下执行的结果一致，程序指令的执行顺序有可能和代码的顺序不一致，这个过程就称之为指令的重排序。指令重排序的意义在于：JVM能根据处理器的特性，充分利用多级缓存，多核等进行适当的指令重排序，使程序在保证业务运行的同时，充分利用CPU的执行特点，最大的发挥机器的性能！

从java源代码到最终执行的指令序列，会经过一下的三种重排序：

> 源代码->编译器优化重排序->指令级并行重排序->内存系统重排序->最终执行的指令序列

为了解决此类额外难题，Java存储模型引入了happens-Before发则，确保并发情况下的数据正确性！通俗的说就是如果动作B要看到动作A的执行结果（无论A/B是否在同一个线程中），那么A/B必须满足happens-before发则！

在说happens-before发则之前我们还得先看另外一个概念：在Java中还有一个概念叫JMMA（Java Memory Medel Action）：Java模型动作。一个Action包含：编写读、变量写、监视器加锁、释放锁、线程启动(start)、线程等待(join)。关于锁我们后续会详细介绍。

说了这么多，那究竟什么是happens-before发则呢？完整的发则如下

（1）同一个线程中的每个Action都happens-before于出现在其后的任何一个Action。

（2）对一个监视器的解锁happens-before于每一个后续对同一个监视器的加锁。

（3）对volatile字段的写入操作happens-before于每一个后续的同一个字段的读操作。

（4）Thread.start()的调用会happens-before于启动线程里面的动作。

（5）Thread中的所有动作都happens-before于其他线程检查到此线程结束或者Thread.join（）中返回或者Thread.isAlive()==false。

（6）一个线程A调用另一个另一个线程B的interrupt（）都happens-before于线程A发现B被A中断（B抛出异常或者A检测到B的isInterrupted（）或者interrupted()）。

（7）一个对象构造函数的结束happens-before与该对象的finalizer的开始

（8）如果A动作happens-before于B动作，而B动作happens-before与C动作，那么A动作happens-before于C动作。


## 多线程常见问题

### 上下文切换

多线程并不一定是要在多核处理器才支持的，就算是单核也是可以支持多线程的。 CPU 通过给每个线程分配一定的时间片，由于时间非常短通常是几十毫秒，所以 CPU 可以不停的切换线程执行任务从而达到了多线程的效果。

但是由于在线程切换的时候需要保存本次执行的信息(在JVM的程序计数器中记录状态，位置)，在该线程被 CPU 剥夺时间片后又再次运行恢复上次所保存的信息的过程就称为上下文切换。

>上下文切换是非常耗效率的。

通常为了避免上下文切换，我们采取了这些方案:

- 采用无锁编程
- 采用CAS算法
- 合理的创建线程，避免创建了一些线程但其中大部分都是处于 waiting 状态，因为每当从 waiting 状态切换到 running 状态都是一次上下文切换。

### 死锁

死锁的场景一般是：线程 A 和线程 B 都在互相等待对方释放锁，或者是其中某个线程在释放锁的时候出现异常如死循环之类的。这时就会导致系统不可用。
常用的解决方案如下：

- 尽量一个线程只获取一个锁。
- 一个线程只占用一个资源。
- 尝试使用定时锁，至少能保证锁最终会被释放。

### 资源限制

当在带宽有限的情况下一个线程下载某个资源需要 1M/S,当开 10 个线程时速度并不会乘 10 倍，反而还会增加时间，毕竟上下文切换比较耗时。



### synchronized 关键字原理

`synchronized`是一种同步锁，被synchronized修饰的东西，在同一个瞬间，只能有一个线程可以进行访问，其中线程会受到阻塞，只有待当前线程执行完以后才能执行。
我们这里称之为线程是互斥的，因为在执行synchronized代码块时会锁定当前的对象，只有执行完该代码块才能释放该对象锁，下一个线程才能执行并锁定该对象。
他可以修饰一下的对象：

- 代码块，被修饰的代码称为**同步代码块**，作用的是调用这个代码块的对象。
  当两个并发线程(thread1和thread2)访问同一个对象(syncThread)中的synchronized代码块时，在同一时刻只能有一个线程得到执行，另一个线程受阻塞，必须等待当前线程执行完这个代码块以后才能执行该代码块。Thread1和thread2是互斥的，因为在执行synchronized代码块时会锁定当前的对象，只有执行完该代码块才能释放该对象锁，下一个线程才能执行并锁定该对象。(如果是不同的对象，那么会产生两个锁，从而并不会互斥)
- 对象
  这时，当一个线程访问对象时，其他试图访问对象的线程将会阻塞，直到该线程访问对象结束。也就是说谁拿到那个锁谁就可以运行它所控制的那段代码。
- 方法，被修饰的代码称为**同步方法**.
  其与代码块synchronized是一致的
  ```java
  public synchronized void method()
    {
    // todo
    }
    public void method()
    {
    synchronized(this) {
        // todo
    }
    }
  ```
- 静态方法，作用对象是这个类的所有对象。
  我们知道静态方法是属于类的而不是属于对象的。因此所有的对象共有一个锁
- 类，作用对象是这个类的所有对象。
  ```java
  class ClassName {
   public void method() {
      synchronized(ClassName.class) {
         // todo
      }
   }
  }
  ```
  与静态方法一致。

总结：
A. 无论synchronized关键字加在方法上还是对象上，如果它作用的对象是非静态的，则它取得的锁是对象；如果synchronized作用的对象是一个静态方法或一个类，则它取得的锁是对类，该类所有的对象同一把锁。
B. 每个对象只有一个锁（lock）与之相关联，谁拿到这个锁谁就可以运行它所控制的那段代码。
C. 实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。


`synchronized`是解决并发问题常用的解决方案，有以下三种使用方式：

- 同步普通方法，锁的是当前对象，进入同步代码前要获取当前对象实例的锁。
- 同步静态方法，锁的当前`Class`对象，进入同步代码前要获取当前类对象的锁。对类进行加锁，会作用于类的所有对象实例。
- 同步块，锁的是代码块内的对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。

>对给定对象加锁，进入同步代码库前要获得给定对象的锁。

同步方法实现原理：为方法添加 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。

同步语句块实现原理：JVM通过进入和退出对象监视器（Monitor）来实现同步的。代码在编译后，会在同步方法调用前面加入一个monitor.enter命令，然后在退出方法和异常处插入monitor.exit的指令。其本质就是对一个对象监视器(Monitor)进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。

我们要认识到synchronized的实现原理属于JVM层面。

在 Java 早期版本中，synchronized 属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。


锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。


### volatile

volatile关键字的作用是保证变量在多线程之间的可见性，他也可以保证有序性。它是java并发开发的核心基础。

- 1.valatile的两层语义
   一旦一个共享变量被volatile修饰后，
   1) 不同线程对这个变量进行操作后，都会立即可见。（修改后，会立即写入主存，会使其他线程的缓存无效）-->可见性
   2) 禁止进行指令重排序。（重排序时，在volatile变量之前的操作已经完成，在volatile之后的没有进行）-->有序性

- 2.实现

有valatile修饰的变量，在其汇编代码之前可以看到 lock，该lock（内存屏障）会触发两件事

    - 将当前处理器缓存行的数据立即写回到系统内存。(一般是写到缓存后，是不确定什么时候会写到内存)
    - 这个写回内存的操作会引起在其他CPU里缓存了该内存地址的数据无效。
    - 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成

- 3.使用条件
  对变量的写操作不依赖于当前值
  该变量没有包含在具有其他变量的不变式中

#### volatile应用场景

状态标记量,如果flag没有用volatile来修饰，就存在某个线程的`stop()`方法修改了flag值，但是不保证确定性，并不会立即刷新到主内存中，导致其他的线程不会立即停止。

```java
 private volatile boolean flag ;
    private void run(){
        new Thread(new Runnable() {
            @Override
            public void run() {
                while (flag) {
                    doSomeThing();
                }
            }
        });
    }

    private void stop(){
        flag = false ;
    }
```

双重检查锁的单例模式

```java
 public class Singleton {
        private static volatile Singleton singleton;

        private Singleton() {
        }

        public static Singleton getInstance() {
            if (singleton == null) {
                synchronized (Singleton.class) {
                    if (singleton == null) {
                        singleton = new Singleton();
                    }
                }
            }
            return singleton;
        }

    }
```

我们注意这里volatile的用法是为了避免指令重排，对于`singleton=new Singleton();` 其代码执行其实分为3个步骤：

- 为singleton分配内存空间
- 初始化singleton
- 将singleton指向分配的内存地址

当多线程并发调用getInstance()时，如果不使用volatile,会出现T1执行了1，3，2。T2访问时发现singleton！=null，从而返回singleton，然后此时singleton并未初始化的问题。




## 线程

### ThreadLocal

Thread类中有一个成员变量属于ThreadLocalMap类(一个定义在ThreadLocal类中的内部类)，它是一个Map，他的key是ThreadLocal实例对象。
当为ThreadLocal类的对象set值时，首先获得当前线程的ThreadLocalMap类属性，然后以ThreadLocal类的对象为key，设定value。get值时则类似。
ThreadLocal变量的活动范围为某线程，是该线程“专有的，独自霸占”的，对该变量的所有操作均由该线程完成！也就是说，ThreadLocal 不是用来解决共享对象的多线程访问的竞争问题的，因为ThreadLocal.set() 到线程中的对象是该线程自己使用的对象，其他线程是不需要访问的，也访问不到的。当线程终止后，这些值会作为垃圾回收。
由ThreadLocal的工作原理决定了：每个线程独自拥有一个变量，并非是共享的。

#### ThreadLocal的内存泄露

由于ThreadLocalMap的key是弱引用，而Value是强引用。这就导致了一个问题，ThreadLocal在没有外部对象强引用时，发生GC时弱引用Key会被回收，而Value不会回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。
如何避免泄漏
既然Key是弱引用，那么我们要做的事，就是在调用ThreadLocal的get()、set()方法时完成后再调用remove方法，将Entry节点和Map的引用关系移除，这样整个Entry对象在GC Roots分析后就变成不可达了，下次GC的时候就可以被回收。
如果使用ThreadLocal的set方法之后，没有显示的调用remove方法，就有可能发生内存泄露，所以养成良好的编程习惯十分重要，使用完ThreadLocal之后，记得调用remove方法。

```java
ThreadLocal<Session> threadLocal = new ThreadLocal<Session>();
try {
    threadLocal.set(new Session(1, "Misout的博客"));
    // 其它业务逻辑
} finally {
    threadLocal.remove();
}
```


### Thread的方法

#### sleep()

sleep(时间)方法需要指定等待的时间,它可以让当前正在执行的线程在指定的时间内暂停执行，进入阻塞状态。可以让`其他同优先级或者高优先级的线程得到执行的机会，也可以让低优先级的线程得到执行机会。`但是sleep()方法不会释放“锁标志”，也就是说如果有synchronized同步块，其他线程仍然不能访问共享数据。

#### yield()

yield()方法和sleep()方法类似，也不会释放“锁标志”，区别在于，它没有参数，即yield()方法只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行，另外yield()方法只能`使同优先级或者高优先级的线程得到执行机会`，这也和sleep()方法不同。

#### join()

当我们调用某个线程的这个方法时，这个方法会挂起调用线程，直到被调用线程结束执行，调用线程才会继续执行。

#### wait()

wait()方法需要和notify()及notifyAll()两个方法一起介绍，这三个方法用于协调多个线程对共享数据的存取，所以必须在synchronized语句块内使用，也就是说，调用wait()，notify()和notifyAll()的任务在调用这些方法前必须拥有对象的锁。注意，它们都是Object类的方法，而不是Thread类的方法。

wait()，notify()及notifyAll()只能在synchronized语句中使用，但是如果使用的是ReenTrantLock实现同步，该如何达到这三个方法的效果呢？解决方法是使用ReenTrantLock.newCondition()获取一个Condition类对象，然后Condition的await()，signal()以及signalAll()分别对应上面的三个方法。

### 线程池

线程资源必须通过线程池提供，不能在应用中自行显示的创建线程。

线程池一般有以下的几个目的：

- 线程是稀缺资源，不能频繁创建。
- 解耦的作用：线程的创建于执行完全分开，方便维护。
- 线程可以为其他任务进行复用。

当然我们在配置线程池的时候，并不是线程池越大越好，通常我们需要根据任务的性质来确定参数：

- IO密集型的任务：由于线程不是一直在运行，所以可以尽可能的多配置线程。
- CPU密集型的任务： 由于线程一直在运行（CPU进行大量的计算），应当分配较少的线程。




### 线程通信

## 阻塞队列

## synchronized和lock

## CAS

CAS(Compare and Swap),比较并替换，是实现并发算法时常用的一种技术。
其实现思想很简单：三个参数，存当前内存值V，旧的预期值A，即将更新的值B。
当且仅当，A和V一致时，将内存值修改为B，并返回true，否则什么都不做，并返回false。

这种思想存在一个问题:A和V一致，就能说明A的值没有被修改过吗？是可能存在A被修改成了C，再从C变回A的情况。针对这种情况，需要对其添加一个标记，通过版本来识别CAS的正确性。
 

## 锁

### 偏向锁

在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。偏向锁在无竞争的情况下会把整个同步都给消除掉。

偏向锁的"偏"，是偏向于第一个获得它的线程的意思。如果在接下来的执行中，该锁没有被其他线程获取，那么持有偏向锁的线程就不需要进行同步！

但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。

### 轻量级锁

轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作。

轻量级锁能够提升程序同步性能的依据是“对于绝大部分锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用 CAS 操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！

### 自旋锁和自适应自旋

轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。

互斥同步对性能最大的影响就是阻塞的实现，因为挂起线程/恢复线程的操作都需要转入内核态中完成（用户态转换到内核态会耗费时间）。

一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。 所以，虚拟机的开发团队就这样去考虑：“我们能不能让后面来的请求获取锁的线程等待一会而不被挂起呢？看看持有锁的线程是否很快就会释放锁”。为了让一个线程等待，我们只需要让线程执行一个忙循环（自旋），这项技术就叫做自旋。

而自适应的自旋锁带来的改进就是：自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定，虚拟机变得越来越“聪明”了。

### 锁消除

锁消除理解起来很简单，它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。

### 锁粗化

原则上，我们再编写代码的时候，总是推荐将同步快的作用范围限制得尽量小——只在共享数据的实际作用域才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待线程也能尽快拿到锁。

### 重入锁

重入锁:一个线程获取了锁之后，仍然可以反复的加锁，不会出现自身阻塞自己的情况。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。

#### ReentrantLock

`ReentrantLock`获取锁的时候会判断当前线程是否为获取锁的线程，如果是，则将同步的状态+1，释放锁的时候将状态-1。只有同步状态的次数为0时，才会最终释放锁。

ReentrantLock 就是一个普通的类，它是基于 AQS(AbstractQueuedSynchronizer)来实现的。需要lock(),unlock()方法配合try/finally语句块来实现。

ReenTrantLock 比 synchronized 增加了一些高级功能：

- 等待可中断，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
- 公平锁和非公平锁，ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。
- 可实现选择性通知，线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” 。

#### synchronized

使用 synchronized 来做同步处理时，锁的获取和释放都是隐式的，实现的原理是通过编译后加上不同的机器指令来实现。

synchronized 依赖于 JVM

### 非公平锁

```java
//默认非公平锁
    public ReentrantLock() {
        sync = new NonfairSync();
    }
```

### 公平锁

```java
//公平锁
    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }
```

### 公平锁和非公平锁的区别

公平锁就相当于买票，后来的人需要排到队尾依次买票，`不能插队`。
而非公平锁则没有这些规则，是`抢占模式`，每来一个人不会去管队列如何，直接尝试获取锁。

由于公平锁需要关心队列的情况，得按照队列里的先后顺序来获取锁(会造成大量的线程上下文切换)，而非公平锁则没有这个限制。
所以也就能解释非公平锁的效率会被公平锁更高。

ReenTrantLock 可以实现公平锁，而synchronized只能是非公平锁。


## 秒杀系统


# 并发的三个核心概念










# 锁的相关认知



# 线程Thread



# 线程池



## Executors

我们在配置一个线程池的时候，是非常复杂的。我们可以利用`ThreadPoolExecutor`来实现线程池，他通过构造方法的一系列参数，来构建不同配置的线程池。
我们在配置线程池的时候，需要思考这么几个问题?

- 线程池里面的线程什么时候创建;
- 线程池大小怎么确定;
- 线程要定时执行吗
- 线程的优先级呢.

因此Executors类里面提供了一些静态工厂，以生成一些常用的线程池。包括：

- newSingleThreadExecutor() 单线程的线程池，这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。
- newFixedThreadPool(int nThreads)  创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，在提交新任务，任务将会进入等待队列中等待。如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。
- newCachedThreadPool() 创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒处于等待任务到来）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池的最大值是Integer的最大值(2^31-1)。
- newScheduledThreadPool() 创建一个定长线程池，支持定时及周期性任务执行。

### 使用

1. execute(Runnable) 接收一個 java.lang.Runnable 对象作为参数，并且以异步的方式执行它。使用这种方式没有办法获取执行 Runnable 之后的结果，如果你希望获取运行之后的返回值。
2. submit(Runnable) 方法 submit(Runnable) 同样接收1个 Runnable 的实现作为参数，但是会返回壹1个Future 对象。这個 Future 对象可以用于判断 Runnable 是否结束执行。

### 缺陷

《阿里开发手册中》，并不推荐我们使用Executors进行线程池的创建，这是为什么呢？

线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式能让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。

主要问题是，针对newSingThreadExecutor 会出现堆积的请求处理队列过大，出现OOM；针对newCachedThreadPool会创建Integer.MAX_VALUE个线程，出现OOM。

## 线程池隔离

比如我们 Tomcat 接受请求的线程池，假设其中一些响应特别慢，线程资源得不到回收释放；线程池慢慢被占满，最坏的情况就是整个应用都不能提供服务。

所以我们需要将线程池进行`隔离`，其实就不同的业务逻辑采用不同的线程，当一个线程池满了之后，不会影响其他的任务。

# 线程通信

开发过程中，存在这样的场景。
所有子线程执行完毕，通知主线程处理某种逻辑的场景。或者线程A在执行到某个条件时通知线程B进行某个操作。

## 等待通知机制

线程A和线程B都对同一个对象获取锁，A线程调用了同步对象的wait()方法释放了锁，并进入WAITING状态。
B线程调用了notify()方法，这样A线程就能从wait()方法中返回。

有一些注意点:

- wait() 、notify()、notifyAll() 调用的前提都是获得了对象的锁
- 调用 wait() 方法后线程会释放锁，进入 WAITING 状态，该线程也会被移动到等待队列中。
- 调用 notify() 方法会将等待队列中的线程移动到同步队列中
- 从 wait() 方法返回的前提是调用 notify() 方法的线程释放锁，wait() 方法的线程获得锁。

等待通知有一个经典范式：

线程 A 作为消费者：
1.获取对象的锁。
2.进入 while(判断条件)，并调用 wait() 方法。
3.当条件满足跳出循环执行具体处理逻辑。

```java
synchronized(Object){
    while(条件){
        Object.wait();
    }
    //do something
}
```

线程 B 作为生产者:

1.获取对象锁。
2.更改与线程 A 共用的判断条件。
3.调用 notify() 方法。

```java
synchronized(Object){
    条件=false;//改变条件
    Object.notify();
}
```

## join()方法

thread.join()对线程进行阻塞，知道线程完成

## volatile共享内存

volatile修饰变量，让其在内存中保持可见性。

## CountDownLatch 并发工具

CountDownLatch 也是基于 AQS(AbstractQueuedSynchronizer) 实现的

1.初始化一个 CountDownLatch 时告诉并发的线程，然后在每个线程处理完毕之后调用 countDown() 方法。
2.该方法会将 AQS 内置的一个 state 状态 -1 。
3.最终在主线程调用 await() 方法，它会阻塞直到 state == 0 的时候返回。

## CyclicBarrier 并发工具

CyclicBarrier 中文名叫做屏障或者是栅栏，也可以用于线程间通信。
它可以等待 N 个线程都达到某个状态后继续运行的效果。

1.首先初始化线程参与者。
2.调用 await() 将会在所有参与者线程都调用之前等待。
3.直到所有参与者都调用了 await() 后，所有线程从 await() 返回继续后续逻辑。

## 线程响应中断

可以采用中断线程的方式来通信，调用了 thread.interrupt() 方法其实就是将 thread 中的一个标志属性置为了 true。

并不是说调用了该方法就可以中断线程，只是标志属性变换。

## 线程池 awaitTermination() 方法

如果是用线程池来管理线程，可以使用以下方式来让主线程等待线程池中所有任务执行完毕:

1.使用这个 awaitTermination() 方法的前提需要关闭线程池，如调用了 shutdown() 方法。
2.调用了 shutdown() 之后线程池会停止接受新任务，并且会平滑的关闭线程池中现有的任务。

## 管道通信

Java 虽说是基于内存通信的，但也可以使用管道通信。

需要注意的是，输入流和输出流需要首先建立连接。这样线程 B 就可以收到线程 A 发出的消息了。

```java
  //面向于字符 PipedInputStream 面向于字节
  PipedWriter writer = new PipedWriter();s
  PipedReader reader = new PipedReader();

  //输入输出流建立连接
  writer.connect(reader);
```

# JUC的Atomic原子类

Atomic就是原子性的意思，体现在一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。

java.util.concurrent.atomic 包含了java并发使用的所有原子类。包括四类：

1. 基本类型，使用原子的方式更新基本类型

    - AtomicInteger：整形原子类
    - AtomicLong：长整型原子类
    - AtomicBoolean ：布尔型原子类

2. 数组类型，使用原子的方式更新数组里的某个元素

    - AtomicIntegerArray：整形数组原子类
    - AtomicLongArray：长整形数组原子类
    - AtomicReferenceArray ：引用类型数组原子类

3. 引用类型

    - AtomicReference：引用类型原子类
    - AtomicStampedRerence：原子更新引用类型里的字段原子类
    - AtomicMarkableReference ：原子更新带有标记位的引用类型

4. 对象的属性修改类型

    - AtomicIntegerFieldUpdater:原子更新整形字段的更新器
    - AtomicLongFieldUpdater：原子更新长整形字段的更新器
    - AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。

# 原子类的优势

①多线程环境不使用原子类保证线程安全

```java
class NoAtomic {
        //使用volatile是内存可见
        private volatile int count = 0;
        //若要线程安全执行执行count++，需要加锁
        public synchronized void increment() {
                  count++;
        }

        public int getCount() {
                  return count;
        }
}
```

②多线程环境使用原子类保证线程安全

```java
class Atomic {
        private AtomicInteger count = new AtomicInteger();
        //使用AtomicInteger之后，不需要加锁，也可以实现线程安全。
        public void increment() {
                  count.incrementAndGet();
        }

       public int getCount() {
                return count.get();
        }
}
```

原子类，主要利用了CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

# AQS

AQS(AbstractQueueSynchronizer)，位于java.util.concurrent.locks包下。

AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。

## AQS原理

AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

>CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。

# 分布式、高并发、多线程的区别

分布式=高并发=多线程？然而并不是，他们三者是相伴而生，但是侧重点又有不同

## 什么是分布式

分布式，**为了解决单个物理服务器容量和性能瓶颈问题而采用的优化手段**。这种手段衍生出了各种系统，包括：分布式文件系统、分布式缓存、分布式数据库以及分布式计算。
特别是经常遇到的那些名词：Hadoop、zookeeper、MQ等都和分布式有关。
从理念上讲，分布式的实现有两种方式：

1. **水平扩展**，当单个服务器扛不住访问时，可以通过添加机器的方式，将流量分解到所有的服务器上，所有的服务器提供的是一样的功能。
2. **垂直拆分**，前端有不同的访问请求，将不同的请求分发到不同的机器上，所有的服务器提供各自服务器承载的功能。

## 什么是高并发

高并发，**反映了同时访问的数量**。高并发可以通过分布式的技术取解决，将并发流量分发到不同的服务器进行处理。除此之外我们也可以采用另外的优化手段：比如使用缓存系统，使用CDN；也可以使用多线程技术使服务器的性能最大化。

## 什么是多线程

多线程，**是指从单个计算机来说，实现多个线程并发执行的技术**。多线程最需要关心的问题就是`线程安全`的问题。

## 总结

- 分布式是从物理资源的角度去将不同的机器组成一个整体对外服务，技术范围非常管且难度非常大，有了这个基础，高并发、高吞吐等系统很容易构建；
- 高并发是从业务角度去描述系统的能力，实现高并发的手段可以采用分布式，也可以采用诸如缓存、CDN等，当然也包括多线程；
- 多线程则聚焦于如何使用编程语言将CPU调度能力最大化。




# 如何创建线程

java 1.5之前，创建启动一个线程可以 继承Thread类，也可以 实现Runnable接口，但是这两种凡是都无法获取执行任务之后的执行结果。
Thread类只支持Runnable

```java
public interface Runnable {//返回值为void，所以无法返回结果
    public abstract void run();
}
```

1.5之后，java提供了Callable和Future接口，实现Callable接口，使用Future结果就可以获取线程运行结果。

# Callable Future 和 FutureTask

`Callable` 接口和 `Runnable` 接口很相似，但是其call方法有返回值，所以可以获取线程执行的返回值。
Thread类不支持Callable，因此需要使用ExecuteService来执行。

```java
public interface Callable<V> {
    V call() throws Exception;
}
```

`Future`就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果等操作。
`Future` 接口 声明了5个方法，分别是：
1) cancel()      用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。
2) isCancelled() 表示任务是否被取消成功。
3) isDone()      表示任务是否完成。
4) get()         获取任务的执行结果，这个方法会产生 **阻塞** ，一直等到任务执行完毕才返回。
5) get(long timeout,TimeUnit unit)   获取任务执行结果，如果在timeout时间内没有获取到结果，就直接返回null。
>Future可以判断任务是否完成，能够中断任务，能够获取任务执行结果。但是future只是接口，是无法直接用来创建对象使用的，因此有了FutureTask。

`FutureTask`  实现了 RunnableFuture<V> 接口->RunnableFuture<V>接口实现了Future和Runnable接口
1)FutureTask是Future接口的一个唯一实现类。
2)FutureTask实现了Runnable，因此它既可以通过Thread包装来直接执行，也可以提交给ExecuteService(->Callable)来执行。

```java
public interface ExecutorService extends Executor {
    <T> Future<T> submit(Callable<T> task);//常用
    <T> Future<T> submit(Runnable task, T result);
    Future<?> submit(Runnable task);//常用

    <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks);
    <T> T invokeAny(Collection<? extends Callable<T>> tasks);
}
```

3)FutureTask实现了Futrue可以直接通过get()函数获取执行结果，该函数会阻塞，直到结果返回。

另外它还可以包装Runnable和Callable，由构造函数注入

```java
 public FutureTask(Callable<V> callable) {
    if (callable == null)
        throw new NullPointerException();
    this.callable = callable;
    this.state = NEW;       // ensure visibility of callable
}

public FutureTask(Runnable runnable, V result) {
    this.callable = Executors.callable(runnable, result);
    this.state = NEW;       // ensure visibility of callable
}
```

我们能看出，Runnable最后也会被转换为Callable执行，即FutureTask最终都是执行Callable类型的任务。

这里我们将介绍使用流程：
1.创建Runnable实现类对象或者Callable实现类对象。
2.创建FutureTash对象，将Runnable实现类对象或者Callable实现类对象作为参数、
3.创建Thread `Thread thread=new Thread(futureTask)`，利用thread对象.start()启动，或者创建线程池`ExecutorService executor = Executors.newCachedThreadPool()`,
利用excutor.submit(futureTask)启动针对Callable 有返回值， excutor.execute(futureTask)针对Runnable，无返回值。
4.利用futureTask.get()获取真正的结果。





## 7.进程和线程

线程与进程相似，但线程是一个比进程更小的执行单位。
一个进程在其执行的过程中可以产生多个线程。
与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。
另外，也正是因为共享资源，所以线程中执行时一般都要进行同步和互斥。
总的来说，进程和线程的主要差别在于它们是不同的操作系统资源管理方式。


### 进程之间的通信

1. 管道（pipe）：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有血缘关系的进程间使用。进程的血缘关系通常指父子进程关系。管道分为pipe（无名管道）和fifo（命名管道）两种，有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间通信。
2. 信号量（semophore）：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它通常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
3. 消息队列（message queue）：消息队列是由消息组成的链表，存放在内核中 并由消息队列标识符标识。消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。
4. 信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某一事件已经发生。
5. 共享内存（shared memory）：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问，共享内存是最快的IPC方式，它是针对其他进程间的通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量配合使用，来实现进程间的同步和通信。
6. 套接字（socket）：套接口也是一种进程间的通信机制，与其他通信机制不同的是它可以用于不同及其间的进程通信。

### 线程之间的通信

线程间通信的主要目的是用于线程同步，所以线程没有象进程通信中用于数据交换的通信机制。

1. 锁机制

互斥锁：提供了以排它方式阻止数据结构被并发修改的方法。
读写锁：允许多个线程同时读共享数据，而对写操作互斥。
条件变量：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

2、信号量机制：包括无名线程信号量与有名线程信号量

3、信号机制：类似于进程间的信号处理。









# Java内存模型

Java内存模型很容易会和Java内存结构混淆，但是他们是两个东西。

Java内存模型是根据英文Java Memory Model（JMM）翻译过来的。其实JMM并不像JVM内存结构一样是真实存在的。他只是一个抽象的概念。JSR-133: Java Memory Model and Thread Specification中描述了，JMM是和多线程相关的，他描述了一组规则或规范，这个规范定义了一个线程对共享变量的写入时对另一个线程是可见的。

>Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能得到一致效果的机制及规范。

Java的线程之间是通过共享内存进行通信的。在利用共享内存通信的过程中，一定是存在`可见性、原子性、顺序性`的问题。
Java内存模型就定义了一些语法集，用于规定了共享内存系统中多线程程序读写操作规范，，这些语法集映射到java语言中，就是我们说的`volatile,synchronized`等关键字。

Java内存模型规定所有的变量都是存在主存当中（物理内存），每个线程都有自己的工作内存（CPU高速缓存）。
线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。
并且每个线程不能访问其他线程的工作内存，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。

![JMM](http://www.hollischuang.com/wp-content/uploads/2018/06/11.png)


