---
layout:     post
title:      锁和并发
date:       2018-07-10
author:     Liber Sun
header-img: img/post-basic.jpg
catalog: true
tags:
    - 面试之路
---

# 并发的三个核心概念

1. `原子性`

即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

在java中，对基本数据类型的变量的读取和赋值操作都是原子性操作，即这些操作是不可中断的。Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。
2. `可见性`
现代计算机中，由于 CPU 直接从主内存中读取数据的效率不高，所以都会对应的 CPU 高速缓存，先将主内存中的数据读取到缓存中，线程修改数据之后首先更新到缓存，之后才会更新到主内存。如果此时还没有将数据更新到主内存其他的线程此时来读取就是修改之前的数据。

可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

Java提供了volatile关键字来保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。

另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。
3. `有序性`
有序性：即程序执行的顺序按照代码的先后顺序执行。

```java
   int a=100;//step1
   int b=200;//step2
   int c=a+b;//step3
```

对于以上的代码，正常的执行顺序是`1>>2>>3`。但是JVM有时为了提高整体效率，可能会对指令进行重排序导致最终顺序为`2>>1>>3`。当然JVM不会随意重排，重排的前提是最终结果和代码执行顺序结果应该一致。

重排在单线程中不会存在问题，在多线程会出现数据不一致的问题。

在Java里面，可以通过volatile关键字来保证一定的“有序性”。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。
另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。

在JDK中，JAVA语言为了维持顺序内部的顺序化语义，也就是为了保证程序的最终运行结果需要和在单线程严格意义的顺序化环境下执行的结果一致，程序指令的执行顺序有可能和代码的顺序不一致，这个过程就称之为指令的重排序。指令重排序的意义在于：JVM能根据处理器的特性，充分利用多级缓存，多核等进行适当的指令重排序，使程序在保证业务运行的同时，充分利用CPU的执行特点，最大的发挥机器的性能！

从java源代码到最终执行的指令序列，会经过一下的三种重排序：

> 源代码->编译器优化重排序->指令级并行重排序->内存系统重排序->最终执行的指令序列

为了解决此类额外难题，Java存储模型引入了happens-Before发则，确保并发情况下的数据正确性！通俗的说就是如果动作B要看到动作A的执行结果（无论A/B是否在同一个线程中），那么A/B必须满足happens-before发则！

在说happens-before发则之前我们还得先看另外一个概念：在Java中还有一个概念叫JMMA（Java Memory Medel Action）：Java模型动作。一个Action包含：编写读、变量写、监视器加锁、释放锁、线程启动(start)、线程等待(join)。关于锁我们后续会详细介绍。

说了这么多，那究竟什么是happens-before发则呢？完整的发则如下

（1）同一个线程中的每个Action都happens-before于出现在其后的任何一个Action。

（2）对一个监视器的解锁happens-before于每一个后续对同一个监视器的加锁。

（3）对volatile字段的写入操作happens-before于每一个后续的同一个字段的读操作。

（4）Thread.start()的调用会happens-before于启动线程里面的动作。

（5）Thread中的所有动作都happens-before于其他线程检查到此线程结束或者Thread.join（）中返回或者Thread.isAlive()==false。

（6）一个线程A调用另一个另一个线程B的interrupt（）都happens-before于线程A发现B被A中断（B抛出异常或者A检测到B的isInterrupted（）或者interrupted()）。

（7）一个对象构造函数的结束happens-before与该对象的finalizer的开始

（8）如果A动作happens-before于B动作，而B动作happens-before与C动作，那么A动作happens-before于C动作。

# 多线程常见问题

## 上下文切换

多线程并不一定是要在多核处理器才支持的，就算是单核也是可以支持多线程的。 CPU 通过给每个线程分配一定的时间片，由于时间非常短通常是几十毫秒，所以 CPU 可以不停的切换线程执行任务从而达到了多线程的效果。

但是由于在线程切换的时候需要保存本次执行的信息(在JVM的程序计数器中记录状态，位置)，在该线程被 CPU 剥夺时间片后又再次运行恢复上次所保存的信息的过程就称为上下文切换。

>上下文切换是非常耗效率的。

通常为了避免上下文切换，我们采取了这些方案:

- 采用无锁编程
- 采用CAS算法
- 合理的创建线程，避免创建了一些线程但其中大部分都是处于 waiting 状态，因为每当从 waiting 状态切换到 running 状态都是一次上下文切换。

## 死锁

死锁的场景一般是：线程 A 和线程 B 都在互相等待对方释放锁，或者是其中某个线程在释放锁的时候出现异常如死循环之类的。这时就会导致系统不可用。
常用的解决方案如下：

- 尽量一个线程只获取一个锁。
- 一个线程只占用一个资源。
- 尝试使用定时锁，至少能保证锁最终会被释放。

## 资源限制

当在带宽有限的情况下一个线程下载某个资源需要 1M/S,当开 10 个线程时速度并不会乘 10 倍，反而还会增加时间，毕竟上下文切换比较耗时。

# synchronized 关键字原理

`synchronized`是解决并发问题常用的解决方案，有以下三种使用方式：

- 同步普通方法，锁的是当前对象，进入同步代码前要获取当前对象实例的锁。
- 同步静态方法，锁的当前`Class`对象，进入同步代码前要获取当前类对象的锁。对类进行加锁，会作用于类的所有对象实例。
- 同步块，锁的是代码块内的对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。

>对给定对象加锁，进入同步代码库前要获得给定对象的锁。

同步方法实现原理：为方法添加 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。

同步语句块实现原理：JVM通过进入和退出对象监视器（Monitor）来实现同步的。代码在编译后，会在同步方法调用前面加入一个monitor.enter命令，然后在退出方法和异常处插入monitor.exit的指令。其本质就是对一个对象监视器(Monitor)进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。

我们要认识到synchronized的实现原理属于JVM层面。

在 Java 早期版本中，synchronized 属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

## JDK关于synchronized的优化

锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

# volatile

volatile关键字的作用是保证变量在多线程之间的可见性，他也可以保证有序性。它是java并发开发的核心基础。

- 1.valatile的两层语义
   一旦一个共享变量被volatile修饰后，
   1) 不同线程对这个变量进行操作后，都会立即可见。（修改后，会立即写入主存，会使其他线程的缓存无效）-->可见性
   2) 禁止进行指令重排序。（重排序时，在volatile变量之前的操作已经完成，在volatile之后的没有进行）-->有序性

- 2.实现

有valatile修饰的变量，在其汇编代码之前可以看到 lock，该lock（内存屏障）会触发两件事

    - 将当前处理器缓存行的数据立即写回到系统内存。(一般是写到缓存后，是不确定什么时候会写到内存)
    - 这个写回内存的操作会引起在其他CPU里缓存了该内存地址的数据无效。
    - 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成

- 3.使用条件
  对变量的写操作不依赖于当前值
  该变量没有包含在具有其他变量的不变式中

## volatile应用场景

状态标记量,如果flag没有用volatile来修饰，就存在某个线程的`stop()`方法修改了flag值，但是不保证确定性，并不会立即刷新到主内存中，导致其他的线程不会立即停止。

```java
 private volatile boolean flag ;
    private void run(){
        new Thread(new Runnable() {
            @Override
            public void run() {
                while (flag) {
                    doSomeThing();
                }
            }
        });
    }

    private void stop(){
        flag = false ;
    }
```

双重检查锁的单例模式

```java
 public class Singleton {
        private static volatile Singleton singleton;

        private Singleton() {
        }

        public static Singleton getInstance() {
            if (singleton == null) {
                synchronized (Singleton.class) {
                    if (singleton == null) {
                        singleton = new Singleton();
                    }
                }
            }
            return singleton;
        }

    }
```

我们注意这里volatile的用法是为了避免指令重排，对于`singleton=new Singleton();` 其代码执行其实分为3个步骤：

- 为singleton分配内存空间
- 初始化singleton
- 将singleton指向分配的内存地址

当多线程并发调用getInstance()时，如果不使用volatile,会出现T1执行了1，3，2。T2访问时发现singleton！=null，从而返回singleton，然后此时singleton并未初始化的问题。

# 锁的相关认知

## 偏向锁

在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。偏向锁在无竞争的情况下会把整个同步都给消除掉。

偏向锁的"偏"，是偏向于第一个获得它的线程的意思。如果在接下来的执行中，该锁没有被其他线程获取，那么持有偏向锁的线程就不需要进行同步！

但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。

## 轻量级锁

轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作。

轻量级锁能够提升程序同步性能的依据是“对于绝大部分锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用 CAS 操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！

## 自旋锁和自适应自旋

轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。

互斥同步对性能最大的影响就是阻塞的实现，因为挂起线程/恢复线程的操作都需要转入内核态中完成（用户态转换到内核态会耗费时间）。

一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。 所以，虚拟机的开发团队就这样去考虑：“我们能不能让后面来的请求获取锁的线程等待一会而不被挂起呢？看看持有锁的线程是否很快就会释放锁”。为了让一个线程等待，我们只需要让线程执行一个忙循环（自旋），这项技术就叫做自旋。

而自适应的自旋锁带来的改进就是：自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定，虚拟机变得越来越“聪明”了。

## 锁消除

锁消除理解起来很简单，它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。

## 锁粗化

原则上，我们再编写代码的时候，总是推荐将同步快的作用范围限制得尽量小——只在共享数据的实际作用域才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待线程也能尽快拿到锁。

## 重入锁

重入锁:一个线程获取了锁之后，仍然可以反复的加锁，不会出现自身阻塞自己的情况。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。

### ReentrantLock

`ReentrantLock`获取锁的时候会判断当前线程是否为获取锁的线程，如果是，则将同步的状态+1，释放锁的时候将状态-1。只有同步状态的次数为0时，才会最终释放锁。

ReentrantLock 就是一个普通的类，它是基于 AQS(AbstractQueuedSynchronizer)来实现的。需要lock(),unlock()方法配合try/finally语句块来实现。

ReenTrantLock 比 synchronized 增加了一些高级功能：

- 等待可中断，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
- 公平锁和非公平锁，ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。
- 可实现选择性通知，线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” 。

### synchronized

使用 synchronized 来做同步处理时，锁的获取和释放都是隐式的，实现的原理是通过编译后加上不同的机器指令来实现。

synchronized 依赖于 JVM

## 非公平锁

```java
//默认非公平锁
    public ReentrantLock() {
        sync = new NonfairSync();
    }
```

## 公平锁

```java
//公平锁
    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }
```

## 公平锁和非公平锁的区别

公平锁就相当于买票，后来的人需要排到队尾依次买票，`不能插队`。
而非公平锁则没有这些规则，是`抢占模式`，每来一个人不会去管队列如何，直接尝试获取锁。

由于公平锁需要关心队列的情况，得按照队列里的先后顺序来获取锁(会造成大量的线程上下文切换)，而非公平锁则没有这个限制。
所以也就能解释非公平锁的效率会被公平锁更高。

ReenTrantLock 可以实现公平锁，而synchronized只能是非公平锁。

# 线程Thread

## sleep()

sleep(时间)方法需要指定等待的时间,它可以让当前正在执行的线程在指定的时间内暂停执行，进入阻塞状态。可以让`其他同优先级或者高优先级的线程得到执行的机会，也可以让低优先级的线程得到执行机会。`但是sleep()方法不会释放“锁标志”，也就是说如果有synchronized同步块，其他线程仍然不能访问共享数据。

## yield()

yield()方法和sleep()方法类似，也不会释放“锁标志”，区别在于，它没有参数，即yield()方法只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行，另外yield()方法只能`使同优先级或者高优先级的线程得到执行机会`，这也和sleep()方法不同。

## join()

当我们调用某个线程的这个方法时，这个方法会挂起调用线程，直到被调用线程结束执行，调用线程才会继续执行。

## wait()

wait()方法需要和notify()及notifyAll()两个方法一起介绍，这三个方法用于协调多个线程对共享数据的存取，所以必须在synchronized语句块内使用，也就是说，调用wait()，notify()和notifyAll()的任务在调用这些方法前必须拥有对象的锁。注意，它们都是Object类的方法，而不是Thread类的方法。

wait()，notify()及notifyAll()只能在synchronized语句中使用，但是如果使用的是ReenTrantLock实现同步，该如何达到这三个方法的效果呢？解决方法是使用ReenTrantLock.newCondition()获取一个Condition类对象，然后Condition的await()，signal()以及signalAll()分别对应上面的三个方法。

# 线程池

线程资源必须通过线程池提供，不能在应用中自行显示的创建线程。

线程池一般有以下的几个目的：

- 线程是稀缺资源，不能频繁创建。
- 解耦的作用：线程的创建于执行完全分开，方便维护。
- 线程可以为其他任务进行复用。

当然我们在配置线程池的时候，并不是线程池越大越好，通常我们需要根据任务的性质来确定参数：

- IO密集型的任务：由于线程不是一直在运行，所以可以尽可能的多配置线程。
- CPU密集型的任务： 由于线程一直在运行（CPU进行大量的计算），应当分配较少的线程。

## Executors

我们在配置一个线程池的时候，是非常复杂的。我们可以利用`ThreadPoolExecutor`来实现线程池，他通过构造方法的一系列参数，来构建不同配置的线程池。
我们在配置线程池的时候，需要思考这么几个问题?

- 线程池里面的线程什么时候创建;
- 线程池大小怎么确定;
- 线程要定时执行吗
- 线程的优先级呢.

因此Executors类里面提供了一些静态工厂，以生成一些常用的线程池。包括：

- newSingleThreadExecutor() 单线程的线程池，这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。
- newFixedThreadPool(int nThreads)  创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，在提交新任务，任务将会进入等待队列中等待。如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。
- newCachedThreadPool() 创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒处于等待任务到来）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池的最大值是Integer的最大值(2^31-1)。
- newScheduledThreadPool() 创建一个定长线程池，支持定时及周期性任务执行。

### 使用

1. execute(Runnable) 接收一個 java.lang.Runnable 对象作为参数，并且以异步的方式执行它。使用这种方式没有办法获取执行 Runnable 之后的结果，如果你希望获取运行之后的返回值。
2. submit(Runnable) 方法 submit(Runnable) 同样接收1个 Runnable 的实现作为参数，但是会返回壹1个Future 对象。这個 Future 对象可以用于判断 Runnable 是否结束执行。

### 缺陷

《阿里开发手册中》，并不推荐我们使用Executors进行线程池的创建，这是为什么呢？

线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式能让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。

主要问题是，针对newSingThreadExecutor 会出现堆积的请求处理队列过大，出现OOM；针对newCachedThreadPool会创建Integer.MAX_VALUE个线程，出现OOM。

## 线程池隔离

比如我们 Tomcat 接受请求的线程池，假设其中一些响应特别慢，线程资源得不到回收释放；线程池慢慢被占满，最坏的情况就是整个应用都不能提供服务。

所以我们需要将线程池进行`隔离`，其实就不同的业务逻辑采用不同的线程，当一个线程池满了之后，不会影响其他的任务。

# 线程通信

开发过程中，存在这样的场景。
所有子线程执行完毕，通知主线程处理某种逻辑的场景。或者线程A在执行到某个条件时通知线程B进行某个操作。

## 等待通知机制

线程A和线程B都对同一个对象获取锁，A线程调用了同步对象的wait()方法释放了锁，并进入WAITING状态。
B线程调用了notify()方法，这样A线程就能从wait()方法中返回。

有一些注意点:

- wait() 、notify()、notifyAll() 调用的前提都是获得了对象的锁
- 调用 wait() 方法后线程会释放锁，进入 WAITING 状态，该线程也会被移动到等待队列中。
- 调用 notify() 方法会将等待队列中的线程移动到同步队列中
- 从 wait() 方法返回的前提是调用 notify() 方法的线程释放锁，wait() 方法的线程获得锁。

等待通知有一个经典范式：

线程 A 作为消费者：
1.获取对象的锁。
2.进入 while(判断条件)，并调用 wait() 方法。
3.当条件满足跳出循环执行具体处理逻辑。

```java
synchronized(Object){
    while(条件){
        Object.wait();
    }
    //do something
}
```

线程 B 作为生产者:

1.获取对象锁。
2.更改与线程 A 共用的判断条件。
3.调用 notify() 方法。

```java
synchronized(Object){
    条件=false;//改变条件
    Object.notify();
}
```

## join()方法

thread.join()对线程进行阻塞，知道线程完成

## volatile共享内存

volatile修饰变量，让其在内存中保持可见性。

## CountDownLatch 并发工具

CountDownLatch 也是基于 AQS(AbstractQueuedSynchronizer) 实现的

1.初始化一个 CountDownLatch 时告诉并发的线程，然后在每个线程处理完毕之后调用 countDown() 方法。
2.该方法会将 AQS 内置的一个 state 状态 -1 。
3.最终在主线程调用 await() 方法，它会阻塞直到 state == 0 的时候返回。

## CyclicBarrier 并发工具

CyclicBarrier 中文名叫做屏障或者是栅栏，也可以用于线程间通信。
它可以等待 N 个线程都达到某个状态后继续运行的效果。

1.首先初始化线程参与者。
2.调用 await() 将会在所有参与者线程都调用之前等待。
3.直到所有参与者都调用了 await() 后，所有线程从 await() 返回继续后续逻辑。

## 线程响应中断

可以采用中断线程的方式来通信，调用了 thread.interrupt() 方法其实就是将 thread 中的一个标志属性置为了 true。

并不是说调用了该方法就可以中断线程，只是标志属性变换。

## 线程池 awaitTermination() 方法

如果是用线程池来管理线程，可以使用以下方式来让主线程等待线程池中所有任务执行完毕:

1.使用这个 awaitTermination() 方法的前提需要关闭线程池，如调用了 shutdown() 方法。
2.调用了 shutdown() 之后线程池会停止接受新任务，并且会平滑的关闭线程池中现有的任务。

## 管道通信

Java 虽说是基于内存通信的，但也可以使用管道通信。

需要注意的是，输入流和输出流需要首先建立连接。这样线程 B 就可以收到线程 A 发出的消息了。

```java
  //面向于字符 PipedInputStream 面向于字节
  PipedWriter writer = new PipedWriter();s
  PipedReader reader = new PipedReader();

  //输入输出流建立连接
  writer.connect(reader);
```

# JUC的Atomic原子类

Atomic就是原子性的意思，体现在一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。

java.util.concurrent.atomic 包含了java并发使用的所有原子类。包括四类：

1. 基本类型，使用原子的方式更新基本类型

    - AtomicInteger：整形原子类
    - AtomicLong：长整型原子类
    - AtomicBoolean ：布尔型原子类

2. 数组类型，使用原子的方式更新数组里的某个元素

    - AtomicIntegerArray：整形数组原子类
    - AtomicLongArray：长整形数组原子类
    - AtomicReferenceArray ：引用类型数组原子类

3. 引用类型

    - AtomicReference：引用类型原子类
    - AtomicStampedRerence：原子更新引用类型里的字段原子类
    - AtomicMarkableReference ：原子更新带有标记位的引用类型

4. 对象的属性修改类型

    - AtomicIntegerFieldUpdater:原子更新整形字段的更新器
    - AtomicLongFieldUpdater：原子更新长整形字段的更新器
    - AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。

# 原子类的优势

①多线程环境不使用原子类保证线程安全

```java
class NoAtomic {
        //使用volatile是内存可见
        private volatile int count = 0;
        //若要线程安全执行执行count++，需要加锁
        public synchronized void increment() {
                  count++;
        }

        public int getCount() {
                  return count;
        }
}
```

②多线程环境使用原子类保证线程安全

```java
class Atomic {
        private AtomicInteger count = new AtomicInteger();
        //使用AtomicInteger之后，不需要加锁，也可以实现线程安全。
        public void increment() {
                  count.incrementAndGet();
        }

       public int getCount() {
                return count.get();
        }
}
```

原子类，主要利用了CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

# AQS

AQS(AbstractQueueSynchronizer)，位于java.util.concurrent.locks包下。

AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。

## AQS原理

AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。



>CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。